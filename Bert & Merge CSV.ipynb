{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "encouraging-greeting",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "turned-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm,trange\n",
    "from transformers import *\n",
    "# from ner_eval import classification_report,csv_report,f1_score\n",
    "from seqeval.scheme import IOB2\n",
    "from seqeval.metrics import classification_report,f1_score\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "physical-indonesia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"IOB2_Data/BCSMM4H_train_IOB2_all.txt\",sep = '\\t')\n",
    "data_dev = pd.read_csv(\"IOB2_Data/BC_dev_IOB2_all.txt\",sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hairy-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.fillna('NA')\n",
    "data_dev = data_dev.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complex-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                     s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence#\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "underlying-platinum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data_train)\n",
    "dev_getter = SentenceGetter(data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "through-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
    "dev_sentences = [[word[0] for word in sentence] for sentence in dev_getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tamil-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "dev_labels = [[s[1] for s in sent] for sent in dev_getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "verbal-digit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-', 'I-', 'PAD']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_values = list(set(data_train[\"Tag\"].values))\n",
    "tag_values.append(\"PAD\")\n",
    "tag_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artificial-morgan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4428cfe16916430eb907afe8eb3a4ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3eb21e2f6c4754a3ac5f483732147f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1c76aed49e4fe2a33a584cad15db2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efa918239d84cb5932ec949976ea0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs = 16\n",
    "model_ty = 'bert-base-cased'\n",
    "# model_ty = 'bert-base-multilingual-cased'\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "tokenizer = BertTokenizer.from_pretrained(model_ty, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elegant-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    for word, label in zip(sentence, text_labels):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "        if n_subwords > 1 and 'B-' in label:\n",
    "            labels.extend([label])\n",
    "            _ = 'I-' + label.split('B-')[1]\n",
    "            if _ not in tag_values:\n",
    "                tag_values.append(_)\n",
    "                print(_)\n",
    "            labels.extend([_] * (n_subwords-1))\n",
    "        else:\n",
    "            labels.extend([label] * n_subwords)\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beautiful-benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts_and_labels = [\n",
    "    tokenize_and_preserve_labels(sent, labs)\n",
    "    for sent, labs in zip(sentences, labels)\n",
    "]\n",
    "print('done')\n",
    "dev_tokenized_texts_and_labels = [\n",
    "    tokenize_and_preserve_labels(sent, labs)\n",
    "    for sent, labs in zip(dev_sentences, dev_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smooth-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'B-': 1, 'I-': 2, 'PAD': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "romance-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "tokenized_labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n",
    "\n",
    "dev_tokenized_texts = [token_label_pair[0] for token_label_pair in dev_tokenized_texts_and_labels]\n",
    "dev_tokenized_labels = [token_label_pair[1] for token_label_pair in dev_tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "excessive-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_post_entity(pre_tag,tag):\n",
    "    error_entity = False\n",
    "    if pre_tag == 'O' and 'I-' in tag:\n",
    "        error_entity = True\n",
    "    if error_entity:\n",
    "        print(idx+1)\n",
    "        print(pre_tag,tag)\n",
    "def inspect_label(lal):\n",
    "    for n,_ in enumerate(lal):\n",
    "        if n != 0:\n",
    "            check_post_entity(lal[n-1],lal[n])\n",
    "for idx,t_label in enumerate(dev_tokenized_labels):\n",
    "    inspect_label(t_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "motivated-consequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bruh', 'do', 'you', 'wan', 'na', 'fight', 'nah', 'man', 'it', \"'s\", 'problem']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['B', '##ru', '##h', 'do', 'you', 'wa', '##n', 'na', 'fight', 'na', '##h', 'man', 'it', \"'\", 's', 'problem'] 16\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] 16\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "print(dev_sentences[idx])\n",
    "print(dev_labels[idx])\n",
    "print(dev_tokenized_texts[idx],len(dev_tokenized_texts[idx]))\n",
    "print(dev_tokenized_labels[idx],len(dev_tokenized_labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "crazy-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts]\n",
    "dev_input_ids = [tokenizer.convert_tokens_to_ids(txt) for txt in dev_tokenized_texts]\n",
    "tags = [[tag2idx.get(l) for l in lab] for lab in tokenized_labels]\n",
    "dev_tags = [[tag2idx.get(l,tag2idx['O']) for l in lab] for lab in dev_tokenized_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "artificial-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class BertNerDataset(Dataset):\n",
    "    def __init__(self,sentences,labels, word_pad_idx, tag_pad_idx, max_len = 500):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.word_pad_idx = word_pad_idx\n",
    "        self.tag_pad_idx = tag_pad_idx\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.sentences[index],self.labels[index])\n",
    "        \n",
    "    def collate_fn(self, datasets):\n",
    "        sentences = [dataset[0] for dataset in datasets]\n",
    "        labels = [dataset[1] for dataset in datasets]\n",
    "        max_sent = max([len(data) for data in sentences])\n",
    "        max_len = max([min(len(sentence), self.max_len) for sentence in sentences])\n",
    "        pad_sentence = []\n",
    "        pad_label = []\n",
    "        for sentence,label in zip(sentences,labels):\n",
    "            \n",
    "            if len(sentence) > max_len:\n",
    "#                 print('asd')\n",
    "                pad_sentence.append(sentence[:max_len])\n",
    "                pad_label.append(label[:max_len])\n",
    "                attention_masks = [[float(i != 0.0) for i in ii] for ii in pad_sentence]\n",
    "            else:\n",
    "#                 print('zxc')\n",
    "                pad_sentence.append(sentence+[self.word_pad_idx]*(max_len-len(sentence)))\n",
    "                pad_label.append(label+[self.tag_pad_idx]*(max_len-len(label)))\n",
    "                attention_masks = [[float(i != 0.0) for i in ii] for ii in pad_sentence]\n",
    "        return torch.LongTensor(pad_sentence), torch.LongTensor(pad_label),torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-county",
   "metadata": {},
   "source": [
    "## 使用 trainingset+validset 去做 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "streaming-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader , SubsetRandomSampler ,ConcatDataset,Sampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "bs = 32\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "max_grad_norm = 3.0\n",
    "\n",
    "tr_dataset = BertNerDataset(input_ids,tags,tokenizer.convert_tokens_to_ids('[PAD]'),tag2idx['PAD'])\n",
    "va_dataset = BertNerDataset(dev_input_ids,dev_tags,tokenizer.convert_tokens_to_ids('[PAD]'),tag2idx['PAD'])\n",
    "dataset = ConcatDataset([tr_dataset, va_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sonic-remark",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a01ec3e37a4d94ab0dd030da65acc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010300559680393352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train F1-Score: 0.6196611366043063\n",
      "Average valid loss: 0.006457950304556122\n",
      "valid F1-Score: 0.7840481565086531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:56<53:25, 356.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0036142855641541445\n",
      "train F1-Score: 0.8290674780741005\n",
      "Average valid loss: 0.006658595228652645\n",
      "valid F1-Score: 0.8186046511627907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:51<47:23, 355.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.002001998961711518\n",
      "train F1-Score: 0.9021092482422932\n",
      "Average valid loss: 0.006626694098350256\n",
      "valid F1-Score: 0.8407643312101911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:46<41:27, 355.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0012338430284104557\n",
      "train F1-Score: 0.9305404425099746\n",
      "Average valid loss: 0.008645789705327677\n",
      "valid F1-Score: 0.8202247191011236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:42<35:33, 355.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0007405871852626792\n",
      "train F1-Score: 0.9587272727272728\n",
      "Average valid loss: 0.0075235866816864\n",
      "valid F1-Score: 0.8365384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:36<29:35, 355.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0004726608055252245\n",
      "train F1-Score: 0.970850792494079\n",
      "Average valid loss: 0.009161177788280144\n",
      "valid F1-Score: 0.8469468675654244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:31<23:40, 355.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0002872426495619256\n",
      "train F1-Score: 0.9829332846582092\n",
      "Average valid loss: 0.012121113837340268\n",
      "valid F1-Score: 0.8361581920903955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [41:25<17:44, 354.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00021456576706982444\n",
      "train F1-Score: 0.9891214919096809\n",
      "Average valid loss: 0.011587941954109632\n",
      "valid F1-Score: 0.8417721518987342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [47:17<11:47, 353.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 7.848835306257731e-05\n",
      "train F1-Score: 0.9944246412576547\n",
      "Average valid loss: 0.012812200043680258\n",
      "valid F1-Score: 0.8492706645056727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [53:09<05:53, 353.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 5.801860001436856e-05\n",
      "train F1-Score: 0.9957050169057844\n",
      "Average valid loss: 0.012675779969884391\n",
      "valid F1-Score: 0.8525382755842064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [59:00<00:00, 354.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010397590584645556\n",
      "train F1-Score: 0.6329541414859581\n",
      "Average valid loss: 0.007378790658137258\n",
      "valid F1-Score: 0.7598253275109171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:50<52:34, 350.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0037667803834966506\n",
      "train F1-Score: 0.8314526240372561\n",
      "Average valid loss: 0.005380878076902321\n",
      "valid F1-Score: 0.8161648177496038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:41<46:48, 351.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.002021219261033242\n",
      "train F1-Score: 0.8933727916778764\n",
      "Average valid loss: 0.006275581285326467\n",
      "valid F1-Score: 0.8434712084347121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:33<40:57, 351.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0013019763189155678\n",
      "train F1-Score: 0.9328156041177533\n",
      "Average valid loss: 0.008448480299079542\n",
      "valid F1-Score: 0.859071729957806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:24<35:06, 351.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0008083470246843099\n",
      "train F1-Score: 0.9551101840935885\n",
      "Average valid loss: 0.007771854958751386\n",
      "valid F1-Score: 0.860738255033557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:15<29:15, 351.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0005948000922331964\n",
      "train F1-Score: 0.9673606691517411\n",
      "Average valid loss: 0.007268929254173567\n",
      "valid F1-Score: 0.858044164037855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:06<23:25, 351.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0002949631860914208\n",
      "train F1-Score: 0.9824081669856896\n",
      "Average valid loss: 0.008036635509115108\n",
      "valid F1-Score: 0.8677419354838709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [40:57<17:33, 351.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00020702522031654954\n",
      "train F1-Score: 0.988872674206494\n",
      "Average valid loss: 0.00879899091595925\n",
      "valid F1-Score: 0.8717532467532467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:49<11:42, 351.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00012145452317706941\n",
      "train F1-Score: 0.993335159317082\n",
      "Average valid loss: 0.008899311330500112\n",
      "valid F1-Score: 0.874074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:40<05:51, 351.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 6.054653704617444e-05\n",
      "train F1-Score: 0.9965284122053718\n",
      "Average valid loss: 0.009260144201153384\n",
      "valid F1-Score: 0.8760330578512397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:31<00:00, 351.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010364284250250589\n",
      "train F1-Score: 0.6176109454481669\n",
      "Average valid loss: 0.005584403088626904\n",
      "valid F1-Score: 0.7915611814345992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:50<52:37, 350.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.003929644336650913\n",
      "train F1-Score: 0.8262835860601224\n",
      "Average valid loss: 0.005202563185825998\n",
      "valid F1-Score: 0.8338926174496643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:41<46:47, 350.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0021240697954047717\n",
      "train F1-Score: 0.8905734415410684\n",
      "Average valid loss: 0.006479525819600251\n",
      "valid F1-Score: 0.8216503992901507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:33<40:57, 351.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0013162463003759085\n",
      "train F1-Score: 0.9321698452680821\n",
      "Average valid loss: 0.007594076147445369\n",
      "valid F1-Score: 0.8551959114139693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:24<35:06, 351.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0007841425381393714\n",
      "train F1-Score: 0.9569931333574269\n",
      "Average valid loss: 0.007144531250840339\n",
      "valid F1-Score: 0.8482293423271501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:16<29:16, 351.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0005026943687026957\n",
      "train F1-Score: 0.9667570009033424\n",
      "Average valid loss: 0.00860774533956971\n",
      "valid F1-Score: 0.8559027777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:06<23:24, 351.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0002907239883643496\n",
      "train F1-Score: 0.9818577648766328\n",
      "Average valid loss: 0.008801637264202963\n",
      "valid F1-Score: 0.8629441624365483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [40:57<17:33, 351.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00021214201633998038\n",
      "train F1-Score: 0.9883868626383596\n",
      "Average valid loss: 0.008654695179231685\n",
      "valid F1-Score: 0.8502894954507857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:49<11:42, 351.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00013337289028199462\n",
      "train F1-Score: 0.9919215757465735\n",
      "Average valid loss: 0.01027846563232089\n",
      "valid F1-Score: 0.846938775510204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:40<05:51, 351.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 6.70596025851957e-05\n",
      "train F1-Score: 0.9944580721359134\n",
      "Average valid loss: 0.011055991952465523\n",
      "valid F1-Score: 0.8564058469475494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:32<00:00, 351.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010462310315725866\n",
      "train F1-Score: 0.6140969162995595\n",
      "Average valid loss: 0.005620522901861038\n",
      "valid F1-Score: 0.7370929308975377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:51<52:40, 351.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0037480456058713732\n",
      "train F1-Score: 0.8271259807015962\n",
      "Average valid loss: 0.00906884992205913\n",
      "valid F1-Score: 0.7741027445460944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:42<46:48, 351.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.002055523306747189\n",
      "train F1-Score: 0.8982513364138806\n",
      "Average valid loss: 0.004912522275555679\n",
      "valid F1-Score: 0.8453922315308454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:33<40:59, 351.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0012799652176236852\n",
      "train F1-Score: 0.9325086410769511\n",
      "Average valid loss: 0.007102664044143146\n",
      "valid F1-Score: 0.8526785714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:25<35:08, 351.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0009245742661936412\n",
      "train F1-Score: 0.9484235465646073\n",
      "Average valid loss: 0.006604312358548236\n",
      "valid F1-Score: 0.8622291021671826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:16<29:15, 351.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0005475310849799777\n",
      "train F1-Score: 0.9654542131237434\n",
      "Average valid loss: 0.007297137575721644\n",
      "valid F1-Score: 0.8760330578512396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:07<23:24, 351.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.000389921214560201\n",
      "train F1-Score: 0.9770377824535723\n",
      "Average valid loss: 0.006848287674217235\n",
      "valid F1-Score: 0.8685015290519877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [40:58<17:34, 351.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0002223329275170644\n",
      "train F1-Score: 0.9855152181884855\n",
      "Average valid loss: 0.00713570677732655\n",
      "valid F1-Score: 0.8687643898695319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:50<11:42, 351.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0001493504122863494\n",
      "train F1-Score: 0.9918296153493068\n",
      "Average valid loss: 0.008234415247438202\n",
      "valid F1-Score: 0.8741418764302059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:41<05:51, 351.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 6.458036922568306e-05\n",
      "train F1-Score: 0.9953172344137361\n",
      "Average valid loss: 0.008499362747063562\n",
      "valid F1-Score: 0.8825786646201074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:32<00:00, 351.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010619112649334234\n",
      "train F1-Score: 0.5946446615021892\n",
      "Average valid loss: 0.004563292189038189\n",
      "valid F1-Score: 0.7955326460481099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:50<52:36, 350.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0036960342544249403\n",
      "train F1-Score: 0.8281639928698752\n",
      "Average valid loss: 0.004621115081400056\n",
      "valid F1-Score: 0.8481421647819063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:41<46:47, 350.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0020339947663116954\n",
      "train F1-Score: 0.8984857987635516\n",
      "Average valid loss: 0.00496720556330288\n",
      "valid F1-Score: 0.8402270884022709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:32<40:57, 351.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0013276759863208182\n",
      "train F1-Score: 0.9320703653585927\n",
      "Average valid loss: 0.005253398560863501\n",
      "valid F1-Score: 0.8445199660152931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:23<35:06, 351.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0007769265503547525\n",
      "train F1-Score: 0.9543929640039895\n",
      "Average valid loss: 0.006071394766035479\n",
      "valid F1-Score: 0.8512396694214875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:15<29:16, 351.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0004680271237892598\n",
      "train F1-Score: 0.970737913486005\n",
      "Average valid loss: 0.005937409699352395\n",
      "valid F1-Score: 0.8594249201277955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:07<23:26, 351.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0003239726494092296\n",
      "train F1-Score: 0.9790833030192797\n",
      "Average valid loss: 0.007806699837719307\n",
      "valid F1-Score: 0.8532654792196777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [40:59<17:34, 351.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00021146735855837544\n",
      "train F1-Score: 0.9877893202114089\n",
      "Average valid loss: 0.008864080263384628\n",
      "valid F1-Score: 0.871186440677966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:51<11:43, 351.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00012551743981712937\n",
      "train F1-Score: 0.9905161407988328\n",
      "Average valid loss: 0.007825994530810716\n",
      "valid F1-Score: 0.8673894912427023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:43<05:51, 351.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 5.3947440391570335e-05\n",
      "train F1-Score: 0.9967153284671534\n",
      "Average valid loss: 0.009067950678184812\n",
      "valid F1-Score: 0.8686192468619247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:35<00:00, 351.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 5\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010395915107545705\n",
      "train F1-Score: 0.6322291853178155\n",
      "Average valid loss: 0.005941001323224159\n",
      "valid F1-Score: 0.8125502815768303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:50<52:38, 350.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.003667508953174098\n",
      "train F1-Score: 0.8299660289647774\n",
      "Average valid loss: 0.006073782311379047\n",
      "valid F1-Score: 0.8381877022653722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:43<46:53, 351.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0021246480210243145\n",
      "train F1-Score: 0.893781452192667\n",
      "Average valid loss: 0.006322710444968178\n",
      "valid F1-Score: 0.8361669242658424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:34<41:00, 351.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0013106793228557642\n",
      "train F1-Score: 0.9301989150090415\n",
      "Average valid loss: 0.006327952287803242\n",
      "valid F1-Score: 0.8585055643879171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:26<35:10, 351.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0008418054574466358\n",
      "train F1-Score: 0.9538433581682718\n",
      "Average valid loss: 0.007627752842892788\n",
      "valid F1-Score: 0.8421900161030595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:18<29:18, 351.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0005404249796405928\n",
      "train F1-Score: 0.968952016753164\n",
      "Average valid loss: 0.008543290333444125\n",
      "valid F1-Score: 0.8487886382623224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:10<23:27, 351.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0003839759596555331\n",
      "train F1-Score: 0.977830489918803\n",
      "Average valid loss: 0.007930987227566478\n",
      "valid F1-Score: 0.8426073131955484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [41:01<17:34, 351.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00017883750913700252\n",
      "train F1-Score: 0.9880441726750023\n",
      "Average valid loss: 0.007962270516876353\n",
      "valid F1-Score: 0.8535031847133758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:53<11:43, 351.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.000104702116484436\n",
      "train F1-Score: 0.9933315063487714\n",
      "Average valid loss: 0.0106459215451173\n",
      "valid F1-Score: 0.8621794871794873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:44<05:51, 351.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 6.455916138561432e-05\n",
      "train F1-Score: 0.9963443611771157\n",
      "Average valid loss: 0.011066682064948942\n",
      "valid F1-Score: 0.8647773279352227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:35<00:00, 351.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 6\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.009916022862760155\n",
      "train F1-Score: 0.632951823263242\n",
      "Average valid loss: 0.005738414811655149\n",
      "valid F1-Score: 0.7769667477696673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:50<52:38, 350.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.003717360259605315\n",
      "train F1-Score: 0.8212758374910906\n",
      "Average valid loss: 0.005452642307225803\n",
      "valid F1-Score: 0.8029315960912052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:42<46:50, 351.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0021156910863144728\n",
      "train F1-Score: 0.895551776604314\n",
      "Average valid loss: 0.005406796645912805\n",
      "valid F1-Score: 0.8255250403877221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:34<41:00, 351.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0012913126850735623\n",
      "train F1-Score: 0.9289321789321789\n",
      "Average valid loss: 0.006597456197971736\n",
      "valid F1-Score: 0.8432168968318441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:25<35:09, 351.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0008554321236798477\n",
      "train F1-Score: 0.9527331769799747\n",
      "Average valid loss: 0.0072709152881782115\n",
      "valid F1-Score: 0.8602150537634409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:17<29:18, 351.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00046254875116072495\n",
      "train F1-Score: 0.967765302426657\n",
      "Average valid loss: 0.00860596512928912\n",
      "valid F1-Score: 0.8205128205128206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:09<23:26, 351.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0002968586418750157\n",
      "train F1-Score: 0.9803850345078096\n",
      "Average valid loss: 0.008717319458121603\n",
      "valid F1-Score: 0.8380952380952381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [41:00<17:34, 351.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00020588246405930336\n",
      "train F1-Score: 0.985183165166803\n",
      "Average valid loss: 0.009701195071648855\n",
      "valid F1-Score: 0.8576186511240632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:52<11:43, 351.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00010527408333197412\n",
      "train F1-Score: 0.9925359548516293\n",
      "Average valid loss: 0.011616326019433056\n",
      "valid F1-Score: 0.8592592592592594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:44<05:51, 351.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 6.463680647399269e-05\n",
      "train F1-Score: 0.9954504094631483\n",
      "Average valid loss: 0.01161068773418761\n",
      "valid F1-Score: 0.8576131687242798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:35<00:00, 351.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 7\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.01094859034951836\n",
      "train F1-Score: 0.6111013832953948\n",
      "Average valid loss: 0.005073002643444933\n",
      "valid F1-Score: 0.8253452477660438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:51<52:41, 351.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.003614189915857946\n",
      "train F1-Score: 0.8318536931818181\n",
      "Average valid loss: 0.004698307252133854\n",
      "valid F1-Score: 0.8376623376623376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:42<46:50, 351.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0019407510158849165\n",
      "train F1-Score: 0.8997226943375972\n",
      "Average valid loss: 0.005683108977955569\n",
      "valid F1-Score: 0.8482220294882914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:34<40:59, 351.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0013121395975280367\n",
      "train F1-Score: 0.9281221922731356\n",
      "Average valid loss: 0.005795829508378731\n",
      "valid F1-Score: 0.8731914893617021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:25<35:07, 351.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0007489929644483537\n",
      "train F1-Score: 0.9561537768974522\n",
      "Average valid loss: 0.00739739618034814\n",
      "valid F1-Score: 0.8640533778148458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:16<29:17, 351.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00048310654181766297\n",
      "train F1-Score: 0.9681620839363242\n",
      "Average valid loss: 0.008850167695277219\n",
      "valid F1-Score: 0.8521739130434781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:07<23:25, 351.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0003375704894201808\n",
      "train F1-Score: 0.9797174936617168\n",
      "Average valid loss: 0.00878605346895815\n",
      "valid F1-Score: 0.8507718696397941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [40:59<17:33, 351.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00014753248729570655\n",
      "train F1-Score: 0.9907407407407406\n",
      "Average valid loss: 0.009280496075046654\n",
      "valid F1-Score: 0.8711036225779274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:50<11:42, 351.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 8.982187641564812e-05\n",
      "train F1-Score: 0.9925643815741748\n",
      "Average valid loss: 0.010532027171329134\n",
      "valid F1-Score: 0.8729472774416595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:41<05:51, 351.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 6.713345040867719e-05\n",
      "train F1-Score: 0.9960021806287479\n",
      "Average valid loss: 0.009682968874734604\n",
      "valid F1-Score: 0.8718830610490111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:32<00:00, 351.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 8\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010254553572554113\n",
      "train F1-Score: 0.635567987007128\n",
      "Average valid loss: 0.006625874772852612\n",
      "valid F1-Score: 0.772795216741405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:51<52:47, 351.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0038184477439921834\n",
      "train F1-Score: 0.8329150233058444\n",
      "Average valid loss: 0.006247858544589153\n",
      "valid F1-Score: 0.7944142746314973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:43<46:51, 351.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0020342088391227075\n",
      "train F1-Score: 0.9009237456982431\n",
      "Average valid loss: 0.006416745282685249\n",
      "valid F1-Score: 0.8143621084797554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:34<40:59, 351.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0011900924995240294\n",
      "train F1-Score: 0.9341687097067102\n",
      "Average valid loss: 0.008187172824517456\n",
      "valid F1-Score: 0.8352490421455939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:26<35:10, 351.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0007972500707827399\n",
      "train F1-Score: 0.9535964992250888\n",
      "Average valid loss: 0.0071612350862055715\n",
      "valid F1-Score: 0.8301599390708302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:18<29:18, 351.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0004875239610817754\n",
      "train F1-Score: 0.9685075308078502\n",
      "Average valid loss: 0.008352269258274586\n",
      "valid F1-Score: 0.8448275862068966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:09<23:26, 351.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0003219292405914935\n",
      "train F1-Score: 0.9804065189525728\n",
      "Average valid loss: 0.007770774315853417\n",
      "valid F1-Score: 0.8294515401953418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [41:02<17:35, 351.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00019083096680407705\n",
      "train F1-Score: 0.9868891537544696\n",
      "Average valid loss: 0.009139169438742876\n",
      "valid F1-Score: 0.8522283033620015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [46:53<11:43, 351.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00010250043505302605\n",
      "train F1-Score: 0.9927502982472239\n",
      "Average valid loss: 0.010859682424085247\n",
      "valid F1-Score: 0.8608562691131498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [52:45<05:51, 351.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 8.110883241545672e-05\n",
      "train F1-Score: 0.9937637564196625\n",
      "Average valid loss: 0.009885227958184434\n",
      "valid F1-Score: 0.8562691131498471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [58:36<00:00, 351.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 9\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.010585855822860332\n",
      "train F1-Score: 0.624122191011236\n",
      "Average valid loss: 0.009245978209452619\n",
      "valid F1-Score: 0.6301824212271974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:51<52:46, 351.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0038767488104833143\n",
      "train F1-Score: 0.8328767123287671\n",
      "Average valid loss: 0.006184263521325712\n",
      "valid F1-Score: 0.817792985457656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [11:43<46:52, 351.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0020666174549630054\n",
      "train F1-Score: 0.8927587738782763\n",
      "Average valid loss: 0.0058549825464870595\n",
      "valid F1-Score: 0.8156521739130436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [17:34<41:01, 351.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0013788674585255428\n",
      "train F1-Score: 0.92727599209912\n",
      "Average valid loss: 0.007350436896173686\n",
      "valid F1-Score: 0.8181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [23:27<35:10, 351.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0008291945039487536\n",
      "train F1-Score: 0.9522439068261535\n",
      "Average valid loss: 0.0075223763666332245\n",
      "valid F1-Score: 0.8438893844781445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [29:27<29:33, 354.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0005494420610996219\n",
      "train F1-Score: 0.9689530685920578\n",
      "Average valid loss: 0.00956507042250247\n",
      "valid F1-Score: 0.8280254777070064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [35:37<23:59, 359.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00033341251238605004\n",
      "train F1-Score: 0.97590470174172\n",
      "Average valid loss: 0.010470236516970762\n",
      "valid F1-Score: 0.813126709206928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [41:47<18:09, 363.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00020080217085274998\n",
      "train F1-Score: 0.9854338188727042\n",
      "Average valid loss: 0.01153930407855195\n",
      "valid F1-Score: 0.8354430379746836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [47:53<12:08, 364.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00011826303393007498\n",
      "train F1-Score: 0.9923899257111796\n",
      "Average valid loss: 0.010541966982189488\n",
      "valid F1-Score: 0.8336314847942754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [54:00<06:04, 364.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 5.468315700827773e-05\n",
      "train F1-Score: 0.997009515178976\n",
      "Average valid loss: 0.01181853263300679\n",
      "valid F1-Score: 0.8325952170062001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [1:00:05<00:00, 360.58s/it]\n"
     ]
    }
   ],
   "source": [
    "All_Fold_score = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    train_dataloader = DataLoader(dataset, batch_size=bs,\n",
    "                                  collate_fn=tr_dataset.collate_fn,\n",
    "                                  sampler=train_subsampler)\n",
    "    valid_dataloader = DataLoader(dataset, batch_size=bs,\n",
    "                                  collate_fn=va_dataset.collate_fn,\n",
    "                                  sampler=test_subsampler)\n",
    "\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    model = BertForTokenClassification.from_pretrained(\n",
    "        model_ty,\n",
    "        num_labels=len(tag2idx),\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "    optimizer = AdamW(model.parameters(),lr=3e-5,eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    model.cuda()\n",
    "    all_loader = {\n",
    "    \"train\" : train_dataloader,\n",
    "    \"valid\" : valid_dataloader,\n",
    "    }\n",
    "    Fold_score = []\n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        for loader in all_loader:\n",
    "            total_loss = 0\n",
    "            # Training loop\n",
    "            predictions , true_labels = [], []\n",
    "            for step, batch in enumerate(all_loader[loader]):\n",
    "                if loader == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_labels ,b_input_mask = batch\n",
    "                model.zero_grad()\n",
    "                outputs = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "                loss = outputs[0]\n",
    "                loss.backward()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                if loader == 'train':\n",
    "                    torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                logits = outputs[1].detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "                true_labels.extend(label_ids)\n",
    "\n",
    "            avg_loss = total_loss / len(all_loader[loader])\n",
    "            print(f\"Average {loader} loss: {avg_loss}\")\n",
    "            pred_tags,valid_tags = [],[]\n",
    "            for p, l in zip(predictions, true_labels):\n",
    "                _p = []\n",
    "                _l = []\n",
    "                for p_i, l_i in zip(p, l):\n",
    "                    if tag_values[l_i] != \"PAD\":\n",
    "                        _p.append(tag_values[p_i])\n",
    "                        _l.append(tag_values[l_i])\n",
    "                pred_tags.append(_p)\n",
    "                valid_tags.append(_l)\n",
    "            print(f\"{loader} F1-Score: {f1_score(valid_tags , pred_tags,scheme = IOB2)}\")\n",
    "            if loader == 'valid':\n",
    "                Fold_score.append(f1_score(valid_tags , pred_tags,scheme = IOB2))\n",
    "    if Fold_score != []:\n",
    "        All_Fold_score.append(Fold_score)\n",
    "#             if _ == (epochs - 1):\n",
    "#                 print(classification_report(valid_tags, pred_tags,mode='strict',scheme = IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "purple-mumbai",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "All_score = len(All_Fold_score[0]) * [0]\n",
    "for score in All_Fold_score:\n",
    "    All_score = np.sum([All_score,score], axis = 0)\n",
    "All_score = np.round((All_score / 10),2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "russian-kelly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77, 0.82, 0.83, 0.85, 0.85, 0.85, 0.85, 0.86, 0.86, 0.86])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-sleep",
   "metadata": {},
   "source": [
    "## 單用 trainingset 去做 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "thermal-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bs = 64\n",
    "epochs = 10\n",
    "max_grad_norm = 3.0\n",
    "\n",
    "tr_dataset = BertNerDataset(input_ids,tags,tokenizer.convert_tokens_to_ids('[PAD]'),tag2idx['PAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-forwarding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.015133075965451798\n",
      "train F1-Score: 0.6078832636355549\n",
      "Average valid loss: 0.006847840949128361\n",
      "valid F1-Score: 0.7986171132238549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [04:14<38:13, 254.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.004556785061317847\n",
      "train F1-Score: 0.8348516280328312\n",
      "Average valid loss: 0.0068908819337759105\n",
      "valid F1-Score: 0.8116938950988822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [09:09<37:07, 278.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.002645198684861199\n",
      "train F1-Score: 0.8933200398803589\n",
      "Average valid loss: 0.008843207057789305\n",
      "valid F1-Score: 0.8109028960817717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [14:05<33:24, 286.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0015399439633459976\n",
      "train F1-Score: 0.9380433787864922\n",
      "Average valid loss: 0.007930591535285487\n",
      "valid F1-Score: 0.8378839590443686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████                                             | 4/10 [19:00<28:59, 289.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0008924153075964398\n",
      "train F1-Score: 0.9584787800845123\n",
      "Average valid loss: 0.010086697926703301\n",
      "valid F1-Score: 0.8514680483592401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [23:41<23:53, 286.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0005404584471824448\n",
      "train F1-Score: 0.9739865796488648\n",
      "Average valid loss: 0.010505727719943295\n",
      "valid F1-Score: 0.8452173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████                              | 6/10 [27:59<18:27, 276.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00038990858112814393\n",
      "train F1-Score: 0.9811981566820277\n",
      "Average valid loss: 0.011425018871397265\n",
      "valid F1-Score: 0.8467670504871568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [32:47<14:01, 280.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.00017431509045933054\n",
      "train F1-Score: 0.9886479003230272\n",
      "Average valid loss: 0.01313114168273573\n",
      "valid F1-Score: 0.8476357267950962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [37:38<09:27, 283.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0001395025618654761\n",
      "train F1-Score: 0.9927074679220899\n",
      "Average valid loss: 0.013536095514989957\n",
      "valid F1-Score: 0.8581375108790252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [42:25<04:44, 284.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 5.960426894476368e-05\n",
      "train F1-Score: 0.9957509698873084\n",
      "Average valid loss: 0.014084202973360153\n",
      "valid F1-Score: 0.8524590163934426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [47:28<00:00, 284.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.015206943297377722\n",
      "train F1-Score: 0.6008303153431676\n",
      "Average valid loss: 0.006871790106931978\n",
      "valid F1-Score: 0.8110367892976589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███████▌                                                                   | 1/10 [05:05<45:47, 305.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0045988371938012395\n",
      "train F1-Score: 0.829497247043957\n",
      "Average valid loss: 0.005412186552064951\n",
      "valid F1-Score: 0.8387096774193549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████                                                            | 2/10 [09:00<35:12, 264.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.002301824189832229\n",
      "train F1-Score: 0.9029320706610817\n",
      "Average valid loss: 0.006375025175763661\n",
      "valid F1-Score: 0.8595317725752508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████████████████▌                                                    | 3/10 [12:52<29:05, 249.36s/it]"
     ]
    }
   ],
   "source": [
    "All_Fold_score = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(tr_dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    train_dataloader = DataLoader(dataset, batch_size=bs,\n",
    "                                  collate_fn=tr_dataset.collate_fn,\n",
    "                                  sampler=train_subsampler)\n",
    "    valid_dataloader = DataLoader(dataset, batch_size=bs,\n",
    "                                  collate_fn=va_dataset.collate_fn,\n",
    "                                  sampler=test_subsampler)\n",
    "\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    model = BertForTokenClassification.from_pretrained(\n",
    "        model_ty,\n",
    "        num_labels=len(tag2idx),\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "    optimizer = AdamW(model.parameters(),lr=3e-5,eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    model.cuda()\n",
    "    all_loader = {\n",
    "    \"train\" : train_dataloader,\n",
    "    \"valid\" : valid_dataloader,\n",
    "    }\n",
    "    Fold_score = []\n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        for loader in all_loader:\n",
    "            total_loss = 0\n",
    "            # Training loop\n",
    "            predictions , true_labels = [], []\n",
    "            for step, batch in enumerate(all_loader[loader]):\n",
    "                if loader == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_labels ,b_input_mask = batch\n",
    "                model.zero_grad()\n",
    "                outputs = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "                loss = outputs[0]\n",
    "                loss.backward()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                if loader == 'train':\n",
    "                    torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                logits = outputs[1].detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "                true_labels.extend(label_ids)\n",
    "\n",
    "            avg_loss = total_loss / len(all_loader[loader])\n",
    "            print(f\"Average {loader} loss: {avg_loss}\")\n",
    "            pred_tags,valid_tags = [],[]\n",
    "            for p, l in zip(predictions, true_labels):\n",
    "                _p = []\n",
    "                _l = []\n",
    "                for p_i, l_i in zip(p, l):\n",
    "                    if tag_values[l_i] != \"PAD\":\n",
    "                        _p.append(tag_values[p_i])\n",
    "                        _l.append(tag_values[l_i])\n",
    "                pred_tags.append(_p)\n",
    "                valid_tags.append(_l)\n",
    "            print(f\"{loader} F1-Score: {f1_score(valid_tags , pred_tags,scheme = IOB2)}\")\n",
    "            if loader == 'valid':\n",
    "                Fold_score.append(f1_score(valid_tags , pred_tags,scheme = IOB2))\n",
    "    if Fold_score != []:\n",
    "        All_Fold_score.append(Fold_score)\n",
    "#             if _ == (epochs - 1):\n",
    "#                 print(classification_report(valid_tags, pred_tags,mode='strict',scheme = IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_score = len(All_Fold_score[0]) * [0]\n",
    "for score in All_Fold_score:\n",
    "    All_score = np.sum([All_score,score], axis = 0)\n",
    "All_score = np.round((All_score / 10) , 2)\n",
    "All_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-slovenia",
   "metadata": {},
   "source": [
    "## 全部的 trainingset 訓練 model 後, 透過 validset 評估 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    model_ty,\n",
    "    num_labels=len(tag2idx),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")\n",
    "optimizer = AdamW(model.parameters(),lr=3e-5,eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    "    )\n",
    "model.cuda()\n",
    "train_dataloader = DataLoader(tr_dataset, batch_size=bs,\n",
    "                            collate_fn=tr_dataset.collate_fn)\n",
    "valid_dataloader = DataLoader(va_dataset, batch_size=bs,\n",
    "                            collate_fn=va_dataset.collate_fn)\n",
    "all_loader = {\n",
    "    \"train\" : train_dataloader,\n",
    "    \"valid\" : valid_dataloader,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-affiliation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F_Score = []\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    for loader in all_loader:\n",
    "        total_loss = 0\n",
    "        # Training loop\n",
    "        predictions , true_labels = [], []\n",
    "        for step, batch in enumerate(all_loader[loader]):\n",
    "            if loader == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_labels ,b_input_mask = batch\n",
    "            model.zero_grad()\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                            attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if loader == 'train':\n",
    "                torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "            logits = outputs[1].detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "            true_labels.extend(label_ids)\n",
    "\n",
    "        avg_loss = total_loss / len(all_loader[loader])\n",
    "        print(f\"Average {loader} loss: {avg_loss}\")\n",
    "        pred_tags,valid_tags = [],[]\n",
    "        for p, l in zip(predictions, true_labels):\n",
    "            _p = []\n",
    "            _l = []\n",
    "            for p_i, l_i in zip(p, l):\n",
    "                if tag_values[l_i] != \"PAD\":\n",
    "                    _p.append(tag_values[p_i])\n",
    "                    _l.append(tag_values[l_i])\n",
    "            pred_tags.append(_p)\n",
    "            valid_tags.append(_l)\n",
    "        print(f\"{loader} F1-Score: {f1_score(valid_tags , pred_tags,scheme = IOB2)}\")\n",
    "        if loader == 'valid':\n",
    "            F_Score.append(f1_score(valid_tags , pred_tags,scheme = IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.array(F_Score),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-wages",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
